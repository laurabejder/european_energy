{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data from 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import date\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from playwright.async_api import async_playwright\n",
    "import time\n",
    "import numpy as np\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = [\"01.12.2022\", \"02.12.2022\", \"03.12.2022\", \"04.12.2022\", \"05.12.2022\", \"06.12.2022\", \"07.12.2022\", \"08.12.2022\", \"09.12.2022\", \"10.12.2022\", \"11.12.2022\", \"12.12.2022\", \"13.12.2022\", \"14.12.2022\", \"15.12.2022\", \"16.12.2022\", \"17.12.2022\", \"18.12.2022\", \"19.12.2022\", \"20.12.2022\", \"21.12.2022\", \"22.12.2022\", \"23.12.2022\", \"24.12.2022\", \"25.12.2022\", \"26.12.2022\", \"27.12.2022\", \"28.12.2022\", \"29.12.2022\", \"30.12.2022\", \"31.12.2022\", \"01.01.2023\", \"02.01.2023\", \"03.01.2023\", \"04.01.2023\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/links.csv\")\n",
    "\n",
    "total_df = pd.DataFrame()\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch(headless = False)\n",
    "page = await browser.new_page()\n",
    "\n",
    "url = df.iloc[0]['link']\n",
    "await page.goto(url)\n",
    "\n",
    "time.sleep(1)\n",
    "await page.locator(\"#close-button\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for date in dates:\n",
    "    df = df.replace(to_replace=r'\\d\\d.\\d\\d.202\\d', value= date, regex=True)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        url = row['link']\n",
    "\n",
    "        country = row['country']\n",
    "        area = row['area']\n",
    "    \n",
    "        await page.goto(url)\n",
    "\n",
    "        time.sleep(3)\n",
    "        await page.get_by_text(\"PT60M\").click()\n",
    "\n",
    "        time.sleep(3)\n",
    "\n",
    "        tables = pd.read_html(await page.content(), flavor = 'html5lib')\n",
    "        data = tables[0]\n",
    "        data.insert(0, 'date', date)\n",
    "        data.insert(1, 'country', country)\n",
    "        data.insert(2, 'area', area)\n",
    "        total_df = pd.concat([total_df, data], axis=0)\n",
    "    \n",
    "    print(\"scraped\", date)\n",
    "    print(\"scraped\", url)\n",
    "    total_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.columns = ['date','country', 'area', 'mtu', 'price(currency/mwh)', 'price(eur/mwh)']\n",
    "total_df.tail(50)\n",
    "\n",
    "# Standardize the missing values\n",
    "total_df.replace({'-': np.nan}, inplace=True)\n",
    "total_df.replace({'n/e': np.nan}, inplace=True)\n",
    "\n",
    "# And reorder the columns\n",
    "data = total_df[['date', 'country', 'area', 'mtu', 'price(currency/mwh)', 'price(eur/mwh)']]\n",
    "data.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['price(currency/mwh)'], axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/prices-hourly-111222-201222.csv\", mode='a', index=True, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/prices-hourly-111222-201222.csv\")\n",
    "df['date'] = pd.to_datetime(df['date'],format=\"%d.%m.%Y\")\n",
    "df = df.sort_values(by=['date', 'country','area','mtu'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.drop(['Unnamed: 0'], axis=1)\n",
    "#data = data.drop(['price(currency/mwh)'], axis=1) \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/prices-hourly-011222-040123.csv\", mode='a', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_day = round(data.groupby(['date','country'])['price(eur/mwh)'].mean())\n",
    "data_day = pd.read_csv(\"data/prices-hourly-011222-040123.csv\")\n",
    "data_day = round(data.groupby(['date', 'country']).agg({'price(eur/mwh)': 'mean'}))\n",
    "\n",
    "# Reset the index to get the date on each row.\n",
    "data_day = data_day.reset_index()\n",
    "data_day.tail(50)\n",
    "\n",
    "data_day.to_csv(\"data/prices-daily-011222-040123.csv\", index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0rc2 64-bit ('3.11.0rc2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fa07e5dff76123542c28abca75c0e47ea742948dbeeb360ccfbd2a5c7c277f8b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
